Python has inbuilt Data structures which are used to store and manipulate data. These data structures are:
Inbuilt Simple data structures:
1.None
2.Number
    a. Integer
    b. Float
    c. Complex
3. Booleans
Inbuilt Complex Data Structures:
1.Sequences
    a. Immutable
        1. String
        2. Tuple
        3. Bytes
    b. Mutable
        1. List
        2. Byte Array
        3. Array
2.Set types
    a. Set
    b. Frozenset
3. Map type
    a. Dictionary

User-define Data Stuctures:
1. Stack:Linear, homoenous
    a. LIFO (Last In First Out)
    b. FILO (First In Last Out)
Stack ADT: Stack with the operations on stack is stack ADT
    a. push(item)
    b. pop()
    c. peek()/top()
    d. is_empty()
    e. size()
    f. is_full()
    g. clear()
    h. search(item)
    i. remove(item)
    j. insert(item, index)
    k. delete(index)
    l. reverse()
    m. sort()
    n. concatenate(stack2)
    o. copy()
    p. merge(stack2)
    q. split()
    r. rotate()
    s. flatten()
    t. compress()
    u. decompress()
    v. map(function)
    w. filter(function)
    x. reduce(function)
    y. zip(stack2)
    z. unzip()
2. Queue:
    a. FIFO (First In First Out)
    b. LILO (Last In Last Out)
3. Linked List:
    a. Singly Linked List
    b. Doubly Linked List
    c. Circular Linked List
4. Tree
5. Graph

Linear relationship:
1:Array: Elements linear in memeory
2:LinkedList:Elements are not linear in memory but are linked through pointers
3:Stack:
4:Queue:
5:Hash Table:
6:Hash Map:
7:Hash Set:
8:Hash Table:

Non-Linear relationship:
1.Tree:
2.Graph:
3:Heap:
4:Priority Queue:
5:Binary Search Tree:
6:Binary Tree:
7:AVL Tree:
8:Red-Black Tree:
9:Hash Table:
10:Hash Map:
11:Hash Set:
12:Hash Table:

ADT:
ADT is a theoretical concept in computer science which describes the behavior of a data structure without specifying its implementation.

ADT is a way to define the behavior of a data structure without worrying about the underlying implementation. 

An abstraction is a mechanism for separating uses and implementation of an object.
Two common types of abstractions
procedural or functional abstraction
and data abstraction.

procedural abstracton:
The procedural abstraction is a way of hiding the implementation details of a procedure or function from the user.

Data abstraction:
The data abstraction is a way of hiding the implementation details of a data structure from the user.

ADT are used by set of operations called interface

Constructors Create and initialize new instances of ADT
Accessors: Return data contained in an instance without modifying it
Mutators: Modify the contents of an
ADT instance.
Iterators: Process individual data
components sequentially.

Computational complexity:

Computational complexity is a measure of the amount of computational resources (such as time and memory) required to execute an algorithm. It is used to compare the efficiency of different algorithms and to predict the performance of an algorithm on different inputs.

The computational complexity of an algorithm is usually expressed in terms of the size of the input to the algorithm. For example, the computational complexity of a sorting algorithm might be expressed as O(n log n), where n is the size of the input list.

There are two main types of computational complexity: time complexity and space complexity.
Time complexity is a measure of the amount of time an algorithm takes to execute, usually expressed in terms
of the size of the input. Space complexity is a measure of the amount of memory an algorithm uses, usually expressed in terms of the size of the input.

Analyze complexity:
Pratical/Experimental analysis: Measure the time and space complexity of an algorithm by running it on a variety of inputs and measuring the resources used.
Functional/Theoretical analysis: Analyze the time and space complexity of an algorithm using mathematical techniques such as asymptotic analysis.

order of n/asymptotic analysis:
It is the analytical process to find the space or time complexity in terms of n (input size)
1:f(n) = 100n +1
2:f(n) = n^2 + 2n + 1
3: f(n) = 700
hence the order of n is n^2 for 2 solution algorithm, n for 1 ,and 1 for 3algo by aysmptotic analysis.

To find order of n we use aysmptotic analysis.
aysmptote:
when we represnt something upto a certain limit or infinity
It is the best method but accurate

Analysis Cases of aysmptote:
Good: when the value of n is small, so time execution is small
Bad: when the value of n is large, so time execution is large
Average: Average
*always write a algo on worst case

Linear search program:
Linear search is a simple search algorithm that searches for an element in a list by checking each element in the list one by one until the element is found or the end of the list is reached.
eg in linear search of key = 1 in a list of [2,4,5,6,1,9]
Best case is when 2 is searched
Worst case is when 9 is searched
Average case is when 5 is searched

Binary search program:
Binary search is a search algorithm that finds the position of a target value within a sorted array. It works by repeatedly dividing the search interval in half. If the value of the search key is less than the item in the middle of the interval, the search continues in the lower half, otherwise it continues in the upper half. This process continues until the value is found or the interval is empty.

Bubble sort program:
Bubble sort is a simple sorting algorithm that repeatedly steps through the list, compares adjacent elements and swaps them if they are in the wrong order. The pass through the list is repeated until the list is sorted.

As there are three analysis cases, there are 3 aysmptote notation

1:Big O notation(worst case)
2:Big Omega notation(best case)
3:Big Theta notation(average case)

Big O notation:
Big O notation is a mathematical notation that describes the limiting behavior of a function when the argument tends towards a particular value or infinity. It is used to describe the time complexity of an algorithm.

Big O notations:
O(1) - constant time complexity: the algorithm takes the same amount of time regardless of the size of the input.
O(log n) - logarithmic time complexity: the algorithm takes time proportional to the logarithm of the size of the input.The program runs less than the size of the input. Size of input decreases in each step eg binary seacrh 
O(n) - linear time complexity: the algorithm takes time proportional to the size of the input. eg linear search
O(n log n) - linearithmic time  complexity/Quasilinear:First the complexity increases as n increases and then it decreases eg merge sort
O(n^2) - quadratic time complexity:
The algorithm takes time proportional to the square of the size of the input. eg bubble sort
O(2^n) - exponential time complexity:
The algorithm takes time proportional to 2 raised to the power of the size of the input. eg fibonacci series, recursion
O(n!) - factorial time complexity:
The algorithm takes time proportional to the factorial of the size of the input. eg travelling salesman problem

Time-Space Trade off:
Time-Space Tradeoff is a concept in computer science that refers to the relationship between the time complexity and space complexity of an algorithm. It is a trade-off between the amount of time an algorithm takes to run and the amount of memory it uses.
If we intend to increase the time complexity, space complexity decreases and vice versa

eg Solving fibonacci series using recursion and loop; for recusion time complexity is high O(2^n) and space complexity is low O(1) and for loop time complexity is low O(n) and space complexity is O(n) high

